# 13 - Package Management

## Understanding Package Management Challenges

Managing Kubernetes applications across different environments presents several challenges that every DevOps engineer encounters. When deploying applications to development, staging, and production environments, each environment typically requires different configurations, resource allocations, and security settings. Without proper tooling, managing these variations becomes error-prone and difficult to maintain.

### Core Challenges in Kubernetes Configuration

Configuration Variations Across Environments  
Each environment requires different settings. Development environments might need debug logging and minimal resources, while production requires optimized performance settings, proper resource limits, and security configurations. Managing these differences manually leads to configuration drift and deployment errors.

Template Management and Reusability  
Applications often share common patterns. A typical web application might include a deployment, service, ingress, and ConfigMap. Creating these resources from scratch for each application wastes time and increases the chance of inconsistencies.

Version Control and Release Management  
Tracking which version of an application is deployed where, managing upgrades, and performing rollbacks when issues arise requires systematic approaches to versioning and release management.

Dependency Management  
Modern applications rarely exist in isolation. They depend on databases, message queues, caching systems, and other services. Managing these dependencies and their configurations adds another layer of complexity.

Environment Promotion  
Moving applications from development through staging to production should be predictable and repeatable. Without proper tooling, promoting applications between environments becomes a manual, error-prone process.

### Two Philosophical Approaches

The Kubernetes ecosystem has developed two primary approaches to solving these challenges:

Helm: The Template-Based Approach  
Helm treats Kubernetes applications as packages called charts. It uses Go templates to parameterize Kubernetes manifests, allowing you to define variables and logic within your configuration files. This approach provides powerful templating capabilities and includes built-in release management.

Kustomize: The Patch-Based Approach  
Kustomize takes a different philosophy. Instead of templates, it uses a base configuration with overlays that patch and modify the base for different environments. This approach keeps configurations in plain Kubernetes YAML, making them easier to read and understand without learning a templating language.

## Helm: The Kubernetes Package Manager

Helm has become the de facto standard for packaging and distributing Kubernetes applications. Think of Helm as the apt or yum for Kubernetes, providing a consistent way to package, configure, share, and deploy applications.

### Understanding Helm Architecture

Helm operates with several key components that work together to manage Kubernetes applications:

The Helm Client  
The Helm command-line interface (CLI) is your primary tool for interacting with Helm. It handles chart development, repository management, and release operations. The CLI communicates directly with your Kubernetes cluster using your kubectl configuration.

Charts: The Heart of Helm  
A chart is a collection of files that describe a related set of Kubernetes resources. Charts contain templates, default configuration values, metadata about the package, and documentation. Charts can be stored locally, in Git repositories, or in dedicated chart repositories.

Templates and Values  
Templates are Kubernetes manifest files with Go template directives. These directives allow dynamic content generation based on values provided during installation. Values files contain the configuration parameters that customize the templates for different deployments.

Repositories  
Chart repositories are HTTP servers that house collections of charts. Public repositories like Artifact Hub provide thousands of ready-to-use charts for common applications. Organizations often maintain private repositories for internal applications.

### Benefits of Using Helm

Simplified Application Deployment  
Instead of managing multiple YAML files, Helm packages everything into a single unit. Installing a complex application like WordPress or PostgreSQL becomes a single command.

Configuration Management  
Helm separates configuration from templates, making it easy to deploy the same application with different settings. Development, staging, and production can each have their own values files.

Release Management  
Helm tracks every installation as a release, maintaining a history of deployments. You can upgrade applications to new versions, roll back to previous versions, and see what changed between versions.

Dependency Management  
Charts can declare dependencies on other charts. Installing a web application that requires a database automatically installs and configures both components.

Community Ecosystem  
The Helm community has created thousands of production-ready charts for popular applications. These charts incorporate best practices and are continuously improved by the community.

## Workshop: Mastering Helm Fundamentals

This workshop will guide you through installing Helm, using existing charts, and creating your own charts. By the end, you'll understand how to package and deploy applications using Helm.

### Prerequisites and Setup

Before starting, ensure you have:

- A running Kubernetes cluster (minikube, kind, or cloud-based)
- kubectl installed and configured to communicate with your cluster
- Basic familiarity with Kubernetes concepts (pods, deployments, services)
- A text editor for editing YAML files

### Installing Helm

Helm installation varies by operating system. Choose the method that matches your environment:

```bash
# Universal installation script (works on Linux and macOS)
curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
chmod 700 get_helm.sh
./get_helm.sh

# macOS using Homebrew
brew install helm

# Windows using Chocolatey
choco install kubernetes-helm

# Ubuntu/Debian using apt
curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
sudo apt-get install apt-transport-https --yes
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm

# Verify the installation
helm version --short
```

Expected output should show version 3.x.x. Helm 3 removed the server-side Tiller component, making it more secure and easier to use.

### Working with Helm Repositories

Repositories are collections of charts. Let's add some popular repositories and explore available charts:

```bash
# Add the official Bitnami repository (high-quality, production-ready charts)
helm repo add bitnami https://charts.bitnami.com/bitnami

# Add other useful repositories
helm repo add stable https://charts.helm.sh/stable
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx

# Update your local repository cache
helm repo update

# List all configured repositories
helm repo list

# Search for specific applications
helm search repo wordpress
helm search repo postgresql
helm search repo redis

# Search with more details
helm search repo nginx --versions

# Get detailed information about a specific chart
helm show chart bitnami/nginx
helm show readme bitnami/nginx
helm show values bitnami/nginx > nginx-default-values.yaml
```

The `helm show values` command is particularly useful as it shows all configurable parameters for a chart. Save this output to understand what you can customize.

### Installing and Managing Charts

Let's install an NGINX web server using Helm and explore various installation options:

```bash
# Simple installation with default values
helm install my-web-server bitnami/nginx

# Check the installation status
helm status my-web-server

# List all Helm releases in the current namespace
helm list

# Install with custom parameters using --set
helm install custom-nginx bitnami/nginx \
  --set service.type=LoadBalancer \
  --set replicaCount=3 \
  --set resources.limits.cpu=200m \
  --set resources.limits.memory=256Mi

# Install using a custom values file
cat > my-nginx-values.yaml << 'EOF'
# Number of NGINX replicas
replicaCount: 2

# Image configuration
image:
  registry: docker.io
  repository: bitnami/nginx
  tag: 1.25.3-debian-11-r0
  pullPolicy: IfNotPresent

# Service configuration
service:
  type: NodePort
  port: 80
  nodePort: 30080

# Resource limits and requests
resources:
  limits:
    cpu: 250m
    memory: 256Mi
  requests:
    cpu: 100m
    memory: 128Mi

# Autoscaling configuration
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 5
  targetCPU: 70

# Server block configuration
serverBlock: |-
  server {
    listen 8080;
    server_name _;
    location / {
      default_type text/html;
      return 200 '<html><body><h1>Hello from Helm!</h1></body></html>';
    }
  }
EOF

helm install configured-nginx bitnami/nginx -f my-nginx-values.yaml

# Install in a specific namespace
kubectl create namespace web-apps
helm install -n web-apps namespaced-nginx bitnami/nginx

# Install with a specific version
helm install versioned-nginx bitnami/nginx --version 13.2.34

# Perform a dry run to see what would be installed
helm install test-nginx bitnami/nginx --dry-run --debug
```

### Managing Releases

Once applications are installed, Helm provides comprehensive management capabilities:

```bash
# View all releases across all namespaces
helm list --all-namespaces

# Get detailed information about a release
helm get values my-web-server
helm get manifest my-web-server
helm get notes my-web-server
helm get all my-web-server

# View release history
helm history my-web-server

# Upgrade a release with new values
helm upgrade my-web-server bitnami/nginx \
  --set replicaCount=5 \
  --set service.type=LoadBalancer

# Upgrade using a new values file
cat > upgrade-values.yaml << 'EOF'
replicaCount: 4
resources:
  limits:
    cpu: 300m
    memory: 512Mi
EOF

helm upgrade my-web-server bitnami/nginx -f upgrade-values.yaml

# Roll back to a previous revision
helm rollback my-web-server 1

# Roll back to a specific revision
helm rollback my-web-server 2

# Uninstall a release
helm uninstall my-web-server

# Uninstall and keep history
helm uninstall my-web-server --keep-history

# List all releases including uninstalled ones with kept history
helm list --uninstalled
```

## Creating Custom Helm Charts

While using existing charts is convenient, you'll often need to create custom charts for your applications. Let's build a complete chart from scratch.

### Generating the Chart Structure

```bash
# Create a new chart
helm create webapp-chart

# Examine the generated structure
ls -la webapp-chart/
tree webapp-chart/  # If tree is installed
```

The generated structure includes:

- `Chart.yaml`: Metadata about your chart
- `values.yaml`: Default configuration values
- `templates/`: Directory containing Kubernetes manifest templates
- `charts/`: Directory for chart dependencies
- `.helmignore`: Patterns to ignore when packaging

### Understanding Chart.yaml

Let's create a comprehensive Chart.yaml file:

```yaml
# webapp-chart/Chart.yaml
apiVersion: v2
name: webapp-chart
description: A comprehensive Helm chart for deploying web applications
type: application
version: 1.0.0
appVersion: "2.0.0"
keywords:
  - web
  - application
  - nginx
home: https://github.com/yourorg/webapp
sources:
  - https://github.com/yourorg/webapp
maintainers:
  - name: DevOps Team
    email: devops@example.com
    url: https://example.com
dependencies:
  - name: redis
    version: 17.x.x
    repository: https://charts.bitnami.com/bitnami
    condition: redis.enabled
annotations:
  category: WebApplication
  licenses: Apache-2.0
```

### Creating Comprehensive values.yaml

The values.yaml file defines all configurable parameters:

```yaml
# webapp-chart/values.yaml

# Global values that can be accessed by subcharts
global:
  storageClass: standard
  environment: development

# Replica configuration
replicaCount: 2

# Image configuration
image:
  registry: docker.io
  repository: nginx
  tag: "1.25-alpine"
  pullPolicy: IfNotPresent
  pullSecrets: []

# Service account configuration
serviceAccount:
  create: true
  annotations: {}
  name: ""
  automountServiceAccountToken: true

# Pod security context
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000

# Container security context
securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: true

# Service configuration
service:
  type: ClusterIP
  port: 80
  targetPort: 8080
  nodePort: ""
  loadBalancerIP: ""
  annotations: {}

# Ingress configuration
ingress:
  enabled: false
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  hosts:
    - host: webapp.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: webapp-tls
      hosts:
        - webapp.example.com

# Resource limits and requests
resources:
  limits:
    cpu: 200m
    memory: 256Mi
  requests:
    cpu: 100m
    memory: 128Mi

# Horizontal Pod Autoscaler
autoscaling:
  enabled: false
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# Persistence configuration
persistence:
  enabled: false
  storageClass: ""
  accessMode: ReadWriteOnce
  size: 8Gi
  mountPath: /data
  annotations: {}

# Probes configuration
livenessProbe:
  enabled: true
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3
  successThreshold: 1

readinessProbe:
  enabled: true
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3
  successThreshold: 1

# Node selection
nodeSelector: {}

# Tolerations for pod assignment
tolerations: []

# Affinity rules
affinity: {}

# Additional environment variables
env: []
  # - name: LOG_LEVEL
  #   value: debug

# ConfigMap data
configMap:
  enabled: false
  data: {}

# Secret data
secret:
  enabled: false
  data: {}

# Redis subchart configuration
redis:
  enabled: false
  auth:
    enabled: true
    password: "changeme"
```

### Creating Advanced Templates

Let's create sophisticated templates that handle various scenarios:

```yaml
# webapp-chart/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "webapp-chart.fullname" . }}
  labels:
    {{- include "webapp-chart.labels" . | nindent 4 }}
  annotations:
    checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
    checksum/secret: {{ include (print $.Template.BasePath "/secret.yaml") . | sha256sum }}
spec:
  {{- if not .Values.autoscaling.enabled }}
  replicas: {{ .Values.replicaCount }}
  {{- end }}
  revisionHistoryLimit: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      {{- include "webapp-chart.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      annotations:
        checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
        checksum/secret: {{ include (print $.Template.BasePath "/secret.yaml") . | sha256sum }}
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
      labels:
        {{- include "webapp-chart.selectorLabels" . | nindent 8 }}
        version: {{ .Values.image.tag | quote }}
    spec:
      {{- with .Values.image.pullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "webapp-chart.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      containers:
        - name: {{ .Chart.Name }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
          image: "{{ .Values.image.registry }}/{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - name: http
              containerPort: {{ .Values.service.targetPort }}
              protocol: TCP
          {{- if .Values.livenessProbe.enabled }}
          livenessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: {{ .Values.livenessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.livenessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.livenessProbe.timeoutSeconds }}
            failureThreshold: {{ .Values.livenessProbe.failureThreshold }}
            successThreshold: {{ .Values.livenessProbe.successThreshold }}
          {{- end }}
          {{- if .Values.readinessProbe.enabled }}
          readinessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: {{ .Values.readinessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.readinessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.readinessProbe.timeoutSeconds }}
            failureThreshold: {{ .Values.readinessProbe.failureThreshold }}
            successThreshold: {{ .Values.readinessProbe.successThreshold }}
          {{- end }}
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            {{- range .Values.env }}
            - name: {{ .name }}
              value: {{ .value | quote }}
            {{- end }}
          {{- if .Values.persistence.enabled }}
          volumeMounts:
            - name: data
              mountPath: {{ .Values.persistence.mountPath }}
          {{- end }}
          {{- if .Values.configMap.enabled }}
            - name: config
              mountPath: /etc/config
              readOnly: true
          {{- end }}
      {{- if or .Values.persistence.enabled .Values.configMap.enabled }}
      volumes:
        {{- if .Values.persistence.enabled }}
        - name: data
          persistentVolumeClaim:
            claimName: {{ include "webapp-chart.fullname" . }}
        {{- end }}
        {{- if .Values.configMap.enabled }}
        - name: config
          configMap:
            name: {{ include "webapp-chart.fullname" . }}
        {{- end }}
      {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
```

### Creating Helper Templates

Helper templates provide reusable functions:

```yaml
# webapp-chart/templates/_helpers.tpl
{{/*
Expand the name of the chart.
*/}}
{{- define "webapp-chart.name" -}}
{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Create a default fully qualified app name.
*/}}
{{- define "webapp-chart.fullname" -}}
{{- if .Values.fullnameOverride }}
{{- .Values.fullnameOverride | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- $name := default .Chart.Name .Values.nameOverride }}
{{- if contains $name .Release.Name }}
{{- .Release.Name | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- printf "%s-%s" .Release.Name $name | trunc 63 | trimSuffix "-" }}
{{- end }}
{{- end }}
{{- end }}

{{/*
Create chart name and version as used by the chart label.
*/}}
{{- define "webapp-chart.chart" -}}
{{- printf "%s-%s" .Chart.Name .Chart.Version | replace "+" "_" | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Common labels
*/}}
{{- define "webapp-chart.labels" -}}
helm.sh/chart: {{ include "webapp-chart.chart" . }}
{{ include "webapp-chart.selectorLabels" . }}
{{- if .Chart.AppVersion }}
app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
{{- end }}
app.kubernetes.io/managed-by: {{ .Release.Service }}
app.kubernetes.io/part-of: {{ include "webapp-chart.name" . }}
environment: {{ .Values.global.environment }}
{{- end }}

{{/*
Selector labels
*/}}
{{- define "webapp-chart.selectorLabels" -}}
app.kubernetes.io/name: {{ include "webapp-chart.name" . }}
app.kubernetes.io/instance: {{ .Release.Name }}
{{- end }}

{{/*
Create the name of the service account to use
*/}}
{{- define "webapp-chart.serviceAccountName" -}}
{{- if .Values.serviceAccount.create }}
{{- default (include "webapp-chart.fullname" .) .Values.serviceAccount.name }}
{{- else }}
{{- default "default" .Values.serviceAccount.name }}
{{- end }}
{{- end }}

{{/*
Return the appropriate apiVersion for HorizontalPodAutoscaler
*/}}
{{- define "webapp-chart.hpa.apiVersion" -}}
{{- if semverCompare ">=1.23-0" .Capabilities.KubeVersion.GitVersion -}}
autoscaling/v2
{{- else -}}
autoscaling/v2beta2
{{- end -}}
{{- end -}}
```

### Additional Templates

Create supporting resource templates:

```yaml
# webapp-chart/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ include "webapp-chart.fullname" . }}
  labels:
    {{- include "webapp-chart.labels" . | nindent 4 }}
  {{- with .Values.service.annotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: http
      protocol: TCP
      name: http
      {{- if and (eq .Values.service.type "NodePort") .Values.service.nodePort }}
      nodePort: {{ .Values.service.nodePort }}
      {{- end }}
  {{- if and (eq .Values.service.type "LoadBalancer") .Values.service.loadBalancerIP }}
  loadBalancerIP: {{ .Values.service.loadBalancerIP }}
  {{- end }}
  selector:
    {{- include "webapp-chart.selectorLabels" . | nindent 4 }}
```

```yaml
# webapp-chart/templates/hpa.yaml
{{- if .Values.autoscaling.enabled }}
apiVersion: {{ include "webapp-chart.hpa.apiVersion" . }}
kind: HorizontalPodAutoscaler
metadata:
  name: {{ include "webapp-chart.fullname" . }}
  labels:
    {{- include "webapp-chart.labels" . | nindent 4 }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{ include "webapp-chart.fullname" . }}
  minReplicas: {{ .Values.autoscaling.minReplicas }}
  maxReplicas: {{ .Values.autoscaling.maxReplicas }}
  metrics:
    {{- if .Values.autoscaling.targetCPUUtilizationPercentage }}
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: {{ .Values.autoscaling.targetCPUUtilizationPercentage }}
    {{- end }}
    {{- if .Values.autoscaling.targetMemoryUtilizationPercentage }}
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: {{ .Values.autoscaling.targetMemoryUtilizationPercentage }}
    {{- end }}
{{- end }}
```

```yaml
# webapp-chart/templates/configmap.yaml
{{- if .Values.configMap.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "webapp-chart.fullname" . }}
  labels:
    {{- include "webapp-chart.labels" . | nindent 4 }}
data:
  {{- toYaml .Values.configMap.data | nindent 2 }}
{{- end }}
```

### Testing and Packaging Charts

```bash
# Validate chart syntax and structure
helm lint webapp-chart

# Test template rendering with default values
helm template test-release webapp-chart

# Test with custom values
helm template test-release webapp-chart --set replicaCount=5

# Debug template rendering
helm template test-release webapp-chart --debug

# Perform a dry run installation
helm install test-release webapp-chart --dry-run --debug

# Install the chart
helm install my-webapp webapp-chart

# Run tests if defined
helm test my-webapp

# Package the chart for distribution
helm package webapp-chart

# Create an index file for a chart repository
helm repo index . --url https://charts.example.com
```

## Kustomize: Configuration Management Without Templates

Kustomize offers a different approach to configuration management. Instead of using templates, it works with plain Kubernetes YAML files and applies patches and overlays to customize them for different environments.

### The Kustomize Philosophy

Kustomize follows several key principles that differentiate it from Helm:

Declarative Configuration  
All configurations are expressed as Kubernetes resources. There's no templating language to learn, and all files are valid Kubernetes YAML that can be applied directly.

Composition Over Inheritance  
Rather than inheriting from parent configurations, Kustomize composes final configurations by combining multiple sources and applying transformations.

Patch-Based Customization  
Environment-specific changes are expressed as patches that modify the base configuration. This makes it clear what changes between environments.

Native Kubernetes Integration  
Kustomize is built into kubectl, requiring no additional tools. The `kubectl apply -k` command processes Kustomize directories directly.

### When Kustomize Excels

Kustomize is particularly effective in several scenarios:

GitOps Workflows  
Since all configurations are plain YAML files, Git diffs clearly show what changed. There's no need to render templates to understand modifications.

Simple Configuration Variations  
When differences between environments are straightforward (replica counts, resource limits, image tags), Kustomize's patch approach is cleaner than templating.

Upstream Customization  
You can customize third-party Kubernetes configurations without modifying the original files, making it easy to track upstream changes.

## Workshop: Mastering Kustomize

Let's build a complete application configuration using Kustomize, demonstrating how to manage multiple environments effectively.

### Creating the Project Structure

```bash
# Create a comprehensive directory structure
mkdir -p kustomize-app/{base,overlays/{development,staging,production},components}

# Final structure:
# kustomize-app/
# ├── base/                     # Base configuration
# │   ├── deployment.yaml
# │   ├── service.yaml
# │   ├── configmap.yaml
# │   ├── secret.yaml
# │   └── kustomization.yaml
# ├── components/               # Reusable components
# │   ├── monitoring/
# │   └── logging/
# └── overlays/                 # Environment-specific configurations
#     ├── development/
#     │   ├── kustomization.yaml
#     │   ├── deployment-patch.yaml
#     │   └── configmap-patch.yaml
#     ├── staging/
#     │   ├── kustomization.yaml
#     │   ├── deployment-patch.yaml
#     │   └── ingress.yaml
#     └── production/
#         ├── kustomization.yaml
#         ├── deployment-patch.yaml
#         ├── hpa.yaml
#         └── ingress.yaml
```

### Building the Base Configuration

Create the foundational resources that will be shared across all environments:

```yaml
# base/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
  labels:
    app: webapp
    component: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webapp
      component: frontend
  template:
    metadata:
      labels:
        app: webapp
        component: frontend
    spec:
      containers:
      - name: webapp
        image: nginx:1.25-alpine
        ports:
        - name: http
          containerPort: 80
          protocol: TCP
        env:
        - name: ENVIRONMENT
          valueFrom:
            configMapKeyRef:
              name: webapp-config
              key: environment
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: webapp-config
              key: log.level
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 100m
            memory: 128Mi
        livenessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config
          mountPath: /etc/nginx/conf.d
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: webapp-config
          items:
          - key: nginx.conf
            path: default.conf
```

```yaml
# base/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp-service
  labels:
    app: webapp
    component: frontend
spec:
  type: ClusterIP
  selector:
    app: webapp
    component: frontend
  ports:
  - name: http
    port: 80
    targetPort: http
    protocol: TCP
```

```yaml
# base/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: webapp-config
  labels:
    app: webapp
    component: configuration
data:
  environment: "base"
  log.level: "info"
  app.name: "webapp"
  nginx.conf: |
    server {
        listen 80;
        server_name localhost;
        
        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
            try_files $uri $uri/ =404;
        }
        
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
        
        error_page 404 /404.html;
        error_page 500 502 503 504 /50x.html;
    }
```

```yaml
# base/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: webapp-secret
  labels:
    app: webapp
    component: secrets
type: Opaque
stringData:
  api-key: "base-api-key"
  database-password: "base-password"
```

```yaml
# base/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: webapp-base
  annotations:
    config.kubernetes.io/local-config: "true"

resources:
- deployment.yaml
- service.yaml
- configmap.yaml
- secret.yaml

commonLabels:
  app.kubernetes.io/name: webapp
  app.kubernetes.io/component: application
  app.kubernetes.io/managed-by: kustomize

commonAnnotations:
  version: "1.0.0"
```

### Development Environment Overlay

Configure the development environment with debugging features and minimal resources:

```yaml
# overlays/development/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: webapp-development

namespace: development

resources:
- ../../base

namePrefix: dev-

commonLabels:
  environment: development
  tier: frontend

commonAnnotations:
  environment: "development"
  managed-by: "kustomize"

replicas:
- name: webapp
  count: 1

images:
- name: nginx
  newTag: 1.25-alpine

configMapGenerator:
- name: webapp-config
  behavior: merge
  literals:
  - environment=development
  - log.level=debug
  - debug.enabled=true
  - feature.flags=experimental

secretGenerator:
- name: webapp-secret
  behavior: replace
  literals:
  - api-key=dev-api-key-12345
  - database-password=dev-password

patches:
- target:
    kind: Deployment
    name: webapp
  patch: |-
    - op: replace
      path: /spec/template/spec/containers/0/resources/requests/cpu
      value: "25m"
    - op: replace
      path: /spec/template/spec/containers/0/resources/requests/memory
      value: "32Mi"
    - op: replace
      path: /spec/template/spec/containers/0/resources/limits/cpu
      value: "100m"
    - op: replace
      path: /spec/template/spec/containers/0/resources/limits/memory
      value: "128Mi"
    - op: add
      path: /spec/template/spec/containers/0/env/-
      value:
        name: DEBUG
        value: "true"

patchesStrategicMerge:
- deployment-patch.yaml
```

```yaml
# overlays/development/deployment-patch.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
spec:
  template:
    spec:
      containers:
      - name: webapp
        env:
        - name: DEV_MODE
          value: "enabled"
        - name: VERBOSE_LOGGING
          value: "true"
```

### Staging Environment Overlay

Configure staging to mirror production more closely:

```yaml
# overlays/staging/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: webapp-staging

namespace: staging

resources:
- ../../base
- ingress.yaml

namePrefix: staging-

commonLabels:
  environment: staging
  tier: frontend

replicas:
- name: webapp
  count: 2

images:
- name: nginx
  newTag: 1.25-alpine

configMapGenerator:
- name: webapp-config
  behavior: merge
  literals:
  - environment=staging
  - log.level=warning
  - cache.enabled=true
  - cache.ttl=300

secretGenerator:
- name: webapp-secret
  behavior: replace
  literals:
  - api-key=staging-api-key-67890
  - database-password=staging-secure-pass

patches:
- target:
    kind: Deployment
    name: webapp
  patch: |-
    - op: replace
      path: /spec/template/spec/containers/0/resources/requests/cpu
      value: "100m"
    - op: replace
      path: /spec/template/spec/containers/0/resources/requests/memory
      value: "128Mi"
    - op: replace
      path: /spec/template/spec/containers/0/resources/limits/cpu
      value: "250m"
    - op: replace
      path: /spec/template/spec/containers/0/resources/limits/memory
      value: "256Mi"

patchesStrategicMerge:
- service-patch.yaml
```

```yaml
# overlays/staging/service-patch.yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp-service
spec:
  type: NodePort
  ports:
  - name: http
    port: 80
    targetPort: http
    nodePort: 31000
```

```yaml
# overlays/staging/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: webapp-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: staging.webapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: webapp-service
            port:
              number: 80
```

### Production Environment Overlay

Configure production with high availability and security:

```yaml
# overlays/production/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: webapp-production

namespace: production

resources:
- ../../base
- hpa.yaml
- ingress.yaml
- pdb.yaml

namePrefix: prod-

commonLabels:
  environment: production
  tier: frontend
  criticality: high

replicas:
- name: webapp
  count: 3

images:
- name: nginx
  newTag: 1.25-alpine
  digest: sha256:abcdef1234567890  # Pin to specific digest for production

configMapGenerator:
- name: webapp-config
  behavior: merge
  literals:
  - environment=production
  - log.level=error
  - cache.enabled=true
  - cache.ttl=3600
  - monitoring.enabled=true
  - metrics.enabled=true

secretGenerator:
- name: webapp-secret
  behavior: replace
  literals:
  - api-key=prod-api-key-secure-xyz
  - database-password=prod-ultra-secure-pass

patches:
- target:
    kind: Deployment
    name: webapp
  patch: |-
    - op: replace
      path: /spec/template/spec/containers/0/resources/requests/cpu
      value: "200m"
    - op: replace
      path: /spec/template/spec/containers/0/resources/requests/memory
      value: "256Mi"
    - op: replace
      path: /spec/template/spec/containers/0/resources/limits/cpu
      value: "500m"
    - op: replace
      path: /spec/template/spec/containers/0/resources/limits/memory
      value: "512Mi"
    - op: add
      path: /spec/template/spec/affinity
      value:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - webapp
              topologyKey: kubernetes.io/hostname
```

```yaml
# overlays/production/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webapp
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
```

```yaml
# overlays/production/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: webapp-ingress
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - webapp.example.com
    secretName: webapp-tls
  rules:
  - host: webapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: webapp-service
            port:
              number: 80
```

```yaml
# overlays/production/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: webapp-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: webapp
```

### Deploying with Kustomize

```bash
# Preview what will be deployed for each environment
kubectl kustomize overlays/development/
kubectl kustomize overlays/staging/
kubectl kustomize overlays/production/

# Deploy to development
kubectl apply -k overlays/development/

# Deploy to staging
kubectl apply -k overlays/staging/

# Deploy to production
kubectl apply -k overlays/production/

# View deployed resources in each environment
kubectl get all -n development -l environment=development
kubectl get all -n staging -l environment=staging
kubectl get all -n production -l environment=production

# Update and redeploy
# Make changes to base or overlays, then:
kubectl apply -k overlays/development/

# Remove deployments
kubectl delete -k overlays/development/
kubectl delete -k overlays/staging/
kubectl delete -k overlays/production/
```

### Advanced Kustomize Features

#### Using Components

Components are reusable pieces of configuration:

```bash
# Create a monitoring component
mkdir -p kustomize-app/components/monitoring
```

```yaml
# components/monitoring/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1alpha1
kind: Component

patches:
- target:
    kind: Deployment
  patch: |-
    - op: add
      path: /spec/template/metadata/annotations/prometheus.io~1scrape
      value: "true"
    - op: add
      path: /spec/template/metadata/annotations/prometheus.io~1port
      value: "9090"
    - op: add
      path: /spec/template/spec/containers/0/ports/-
      value:
        name: metrics
        containerPort: 9090
```

```yaml
# Use the component in production
# overlays/production/kustomization.yaml
components:
- ../../components/monitoring
```

#### Variable Substitution

```yaml
# overlays/production/kustomization.yaml
configMapGenerator:
- name: webapp-config
  behavior: merge
  literals:
  - database.url=postgres://$(DB_HOST):5432/$(DB_NAME)

vars:
- name: DB_HOST
  objref:
    kind: ConfigMap
    name: database-config
    apiVersion: v1
  fieldref:
    fieldpath: data.host
- name: DB_NAME
  objref:
    kind: ConfigMap
    name: database-config
    apiVersion: v1
  fieldref:
    fieldpath: data.name
```

## Comparing Helm and Kustomize

Both tools solve configuration management but with different approaches and trade-offs.

### Feature Comparison

|Aspect|Helm|Kustomize|
|---|---|---|
|Philosophy|Package manager with templates|Configuration overlay system|
|Learning Curve|Moderate (Go templates)|Low (plain YAML)|
|Installation|Separate CLI tool|Built into kubectl|
|Configuration Method|Templates with values|Base plus patches|
|Package Distribution|Chart repositories|Git repositories|
|Release Management|Built-in versioning and rollback|External tooling needed|
|Dependency Management|Native chart dependencies|Manual composition|
|Community Ecosystem|Extensive chart library|Growing adoption|
|Dry Run Capability|Native support|Native support|
|Secret Management|Values files (caution needed)|SecretGenerator|
|Debugging|Template rendering can be complex|Straightforward YAML|

### Decision Framework

Choose Helm When:

- You need sophisticated templating with conditional logic
- Managing third-party applications from public repositories
- Release management with versioning and rollbacks is critical
- Your team is comfortable with Go templates
- You need dependency management between charts
- Distributing applications to external users

Choose Kustomize When:

- You prefer working with plain Kubernetes YAML
- Git-based workflows and clear diffs are important
- Configuration differences between environments are straightforward
- You want to customize upstream configurations without forking
- Built-in kubectl integration is valuable
- Your team is new to Kubernetes configuration management

Consider Using Both: Many organizations use both tools for different purposes. Helm for third-party applications and complex internal services, Kustomize for environment-specific configuration management. You can even use Helm to generate base configurations and Kustomize to customize them per environment.

## Best Practices for Package Management

### General Best Practices

Version Everything  
Track all configurations in version control. Tag releases and maintain clear commit messages describing changes.

Separate Configuration from Code  
Keep application images separate from configuration. Use image tags or digests to reference specific versions.

Use Namespaces  
Deploy different environments to separate namespaces. This provides isolation and makes management easier.

Implement GitOps  
Use Git as the source of truth for your configurations. Tools like ArgoCD or Flux can automatically sync Git repositories with your clusters.

Security First  
Never commit secrets to Git. Use sealed-secrets, external-secrets, or cloud provider secret management solutions.

### Helm Best Practices

Chart Development

- Keep charts simple and focused on a single application
- Provide comprehensive default values with documentation
- Use semantic versioning for charts and applications
- Include NOTES.txt to guide users after installation
- Test charts across different Kubernetes versions

Values Management

- Document all values in values.yaml with comments
- Use `values.schema.json` for validation
- Keep environment-specific values in separate files
- Never put secrets directly in values files

Template Best Practices

- Use helper templates to avoid repetition
- Include proper labels and annotations
- Make resource names predictable and consistent
- Handle optional features with conditional blocks

### Kustomize Best Practices

Structure Organization

- Keep base configurations minimal and environment-agnostic
- Use overlays for all environment-specific changes
- Organize components for reusable functionality
- Maintain clear directory structures

Patch Management

- Prefer strategic merge patches over JSON patches when possible
- Keep patches small and focused
- Document why patches are needed
- Test patches across all environments

Configuration Generation

- Use ConfigMapGenerator and SecretGenerator instead of static files
- Leverage variable substitution for dynamic values
- Keep generated names predictable with nameSuffix
